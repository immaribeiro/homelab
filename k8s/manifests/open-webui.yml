---
# Open WebUI - Modern chat interface for LM Studio
# Access at: https://chat.immas.org
# 
# Features:
# - Beautiful ChatGPT-like interface
# - Works with LM Studio (OpenAI-compatible API)
# - User management & auth
# - Chat history & export
# - Markdown, code highlighting
# - Model switching
#
# Deploy: make deploy-chat

apiVersion: v1
kind: Namespace
metadata:
  name: chat
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: open-webui-data
  namespace: chat
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 2Gi
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: open-webui
  namespace: chat
  labels:
    app: open-webui
spec:
  replicas: 1
  selector:
    matchLabels:
      app: open-webui
  template:
    metadata:
      labels:
        app: open-webui
    spec:
      containers:
      - name: open-webui
        image: ghcr.io/open-webui/open-webui:main
        ports:
        - containerPort: 8080
          name: http
        env:
        # Point to LM Studio via the cluster service
        - name: OPENAI_API_BASE_URLS
          value: "http://lmstudio.ai.svc.cluster.local:1234/v1"
        - name: OPENAI_API_KEYS
          value: "not-needed"
        # WebUI configuration
        - name: WEBUI_NAME
          value: "Homelab Chat"
        - name: WEBUI_URL
          value: "https://chat.immas.org"
        # Enable auth (first user becomes admin)
        - name: ENABLE_SIGNUP
          value: "true"
        - name: DEFAULT_USER_ROLE
          value: "user"
        # Optional: disable analytics
        - name: ENABLE_COMMUNITY_SHARING
          value: "false"
        - name: WEBUI_AUTH
          value: "true"
        volumeMounts:
        - name: data
          mountPath: /app/backend/data
        resources:
          requests:
            memory: "256Mi"
            cpu: "100m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 5
      volumes:
      - name: data
        persistentVolumeClaim:
          claimName: open-webui-data
---
apiVersion: v1
kind: Service
metadata:
  name: open-webui
  namespace: chat
  labels:
    app: open-webui
spec:
  selector:
    app: open-webui
  ports:
  - port: 8080
    targetPort: 8080
    protocol: TCP
    name: http
  type: ClusterIP
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: open-webui
  namespace: chat
  annotations:
    cert-manager.io/cluster-issuer: letsencrypt-dns-prod
    nginx.ingress.kubernetes.io/proxy-body-size: "50m"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "600"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "600"
spec:
  ingressClassName: nginx
  tls:
  - hosts:
    - chat.immas.org
    secretName: wildcard-immas-org-tls
  rules:
  - host: chat.immas.org
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: open-webui
            port:
              number: 8080
